exp_name: 'base_res224'
exp_group: 'leap-objaverseXL'
output_dir: './output/'
log_dir: './log'
workers: 4
print_freq: 100
vis_freq: 500
eval_vis_freq: 10
seed: 42

# dataset config
dataset:
  name: 'objaverseXL'
  category: 'general'
  task: 'singlesequence'
  img_size: 224
  img_size_render: 112
  num_frame: 5
  mask_images: True
  augmentation: False
  train_all_frame: False

# network config
model:
  norm_first: False
  # backbone
  backbone_name: 'dinov2'
  backbone_type: 'vitb14'
  backbone_fix: False
  backbone_out_dim: 768
  # encoder
  encoder_layers: 6
  # pe transformer
  use_neck: False
  neck_scale: 'constant_1' #'channel' #'constant_1'
  neck_layers: 2
  pe_with_spatial_pe: False
  # lifting
  lifting_TXdecoder_permute: False
  use_pe_lifting: False
  lifting_use_conv3d: False
  lifting_layers: 12
  latent_res: 24
  # rendering
  volume_res: 96
  render_feat_dim: 3
  render_feat_raw: False
  render_upsample_parametrize: False
  # others
  rot_representation: 'quat'
  use_flash_attn: True

# render config
render:
  n_pts_per_ray: 64
  volume_size: 1.4
  min_depth: 1.0
  max_depth: 2.7
  camera_z: 1.85 # camera pose T_z, range [1.5, 2.2]
  k_size: 5

# loss config
loss:
  weight_render_rgb: 1.0
  weight_render_mask: 3.0
  weight_perceptual: 0.2
  iter_perceptual: 10000
  weight_feat_render: 5.0

# training config
train:
  resume: False
  lr: 0.0001
  lr_embeddings: 0.0001
  lr_backbone: 0.00001  # 0.00002
  weight_decay: 0.005
  schedular_warmup_iter: 500
  total_iteration: 200000
  batch_size: 4
  accumulation_step: 1
  normalize_img: True
  grad_max: 5.0
  use_amp: True
  use_rand_view: False
  min_rand_view: 3
  use_uncanonicalized_pose: False
  #pretrain_path: 'output/kubric/train_224/base_res224_lr2x_percploss-0.1_res32_encoder-nonfix-1e-5_no-neck_no-feat-render-loss/cpt_best_psnr_27.224168484870876.pth.tar'
  pretrain_path: ''

# test config
test:
  batch_size: 1
  compute_metric: True
